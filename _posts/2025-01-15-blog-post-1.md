---
title: 'Community Notes for Everything'
date: 2025-01-15
permalink: /posts/2025/01/blog-post-1/
tags:
  - CommunityNotes
  - Meta
  - Fact-Checking
---

I was working on my dissertation when I read about the [changes in Meta's fact-checking policy](https://about.fb.com/news/2025/01/meta-more-speech-fewer-mistakes/) last week. These are big news for the fight against misinformation and shifts who has the responsibility to fact-checking. For platform and companies that meant the decision between two approaches: professional fact-checkers or platform users opinions integrated in an algorithm. A third option would be to do nothing, but let's focus on the case that they have to choose a policy. 

When read about them, I liked [Community Notes](https://help.x.com/en/using-x/community-notes) because of its openness, and crowdsource seems more efficient in addressing the problem of misinformation. However, I liked both approaches running in parallel to see how effective they are. Unfortunately, probably they won't share much information about the impact of the policies. I think this decision was made based on profit maximization and Meta trying to avoid the role of censor; they were waiting for the elections to make this move. Leaving the decision to the public could have some advantages, in terms of the scope of fact-checking, the latency to recognize false claims and efficiency. One disadvantage is that the algorithm chosen by to rate notes will impact how users behave and the effectiveness of this approach.

In statistical terms, Zuckerberg explained that one main consequence will be a reduction of type 2 errors when deciding that something is misinformation, increasing type 1 error; creating more exposure to misinformation in their platforms. If this is the best option depends on social preferences; and it is nearly impossible to state which error is more important to minimize (however, there is too much false information around). The government made Meta higher the bar for considering something save after the [criticism](https://www.wired.com/story/inside-facebook-mark-zuckerberg-2-years-of-hell/) from every side after the 2016 election, but for a company, this was an expense they wanted to get rid of. 

I talked to the director of [AnimalPolitico](https://animalpolitico.com/ (a fact checker in Mexico), Daniel Moreno, last summer and he mentioned that the main reason X uses Community Notes is because it's free. They have an incentive to promote the use of professional fact-checkers since an important part of the [income for animal politico](https://animalpolitico.com/quienes-somos) comes from verification services, as well as other sites like [Politifact](https://www.politifact.com/who-pays-for-politifact/). 
However, Meta was looking to eliminate fact-checking before the election, and now they have the government on their side on this. Meta has been regulated, which required censorship of posts, especially by the last administration, which saw the problem of misinformation around COVID-19 as dangerous and [Meta has criticized this](https://www.reuters.com/technology/zuckerberg-says-biden-administration-pressured-meta-censor-covid-19-content-2024-08-27/. However, Facebook has tried to avoid the problem of deciding what is fake and what is not, even when this seems unavoidable.
I think that true information should be a public good on internet, and for this reason fact-checking should be subsidized, through regulation, or direct grant from the government. 

Moving moderators from California to Texas might respond to old criticism from conservatives of tech companies being biased and criticizing how these companies [fight misinformation](https://www.reuters.com/technology/zuckerberg-says-biden-administration-pressured-meta-censor-covid-19-content-2024-08-27/. This physical move also represents the move towards less fact-checking. I see the willingness of the companies to cooperate with the government as a possible way to get money and avoiding regulations. 
I am surprised by the lack of discussion of the fact-checkers' attempts to be unbiased and the evidence that misinformation is generated from all political extremes. 
The time will tell; hopefully, this won't backfire and increase government censorship. This last scenario is what worries me the most. 

The consensus is that the problem is complex, and companies don't want to deal with it. Research has also shown that conservatives are more prone to believe and distribute misinformation, although [other demographics can play a stronger role](https://www.sciencedirect.com/science/article/pii/S0747563224001390) an [political extremists on both sides are prone to share misinformation](https://www.nyu.edu/about/news-publications/news/2024/september/online-misinformation-most-likely-to-be-believed-by-ideological-.html). That means the problem is not only in the extreme right, but any real effort to fight misinformation will mechanically appear biased if there is more people sharing misinformation among them. Unfortunately, this [politicization of fact-checking](https://www.washingtonpost.com/politics/2025/01/10/meta-fact-checking-politics-trump/) has created a hostile environment for verification efforts in the US. At least one fact-checker has already expressed [concern](https://www.politico.com/news/magazine/2025/01/05/newsguard-trump-fcc-ftc-00196285?utm_source=substack&utm_medium=email) about the government possibly censoring their work.

What seems a fact is that professional fact-checking won't come from platforms any more, and the only in-app policy will be the integration of users' opinions using an algorithm like the one implemented by Community Notes to flag post that contain misinformation. We will see what this means for the fight against misinformation.
